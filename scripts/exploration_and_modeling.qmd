---
title: "exploration_2.0"
format: html
---

---
title: "Data Analysis Script"
format: html
---

# Libraries and Packages

```{r packages}
#install needed packages and libraries
install.packages("tidyverse") #general tidyverse functions
install.packages("stargazer") #to create display tables for data and models
library(tidyverse)
library(stargazer)
library(AER) #to help with econometric functions
library(dynlm) #to help with autoregression models
```

# Import Data

Import cleaned data folder

```{r}
#import the full data set (daily data over time period with all variables of interest)
#The date column imports as character so mutate function changes back to date time object
read.csv("../data/cleaned_data/full_data.csv") |>
    mutate(date = parse_date_time(str_extract(
    date, 
    pattern = "[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]"),
    orders = "ymd")) |>
  arrange(date) -> full_data


#Complete WSJ headline data before summarising by day
#The date column imports as character so mutate function changes back to date time object
read.csv("../data/cleaned_data/wsj_data_sent.csv") |>
    mutate(date = parse_date_time(str_extract(
    date, 
    pattern = "[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]"),
    orders = "ymd")) |>
  arrange(date) -> wsj_data_sent


#import PE data
read.csv("../data/cleaned_data/pe_data.csv") -> pe_data

#import SPY data, date column turns to character so parse back to date time object
read_csv("../data/imported_data/spy_data.csv") |>
    mutate(change_percent = parse_number(change_percent)/100,
           date = parse_date_time(date, orders = "mdy"),
           month = month(date), #extract the month from date time object
           year = year(date))-> #extract the monthg from date time object
  spy_data
```

# Exploration

To being to explore the answer to the research questions, how does sentiment in headlines affect changes in valuations, a heat map of correlations between variables is created

```{r}
#using the full data set create the heat map of variable correlations
full_data |>
  select(2:8)|>
  cor() |>
  reshape2::melt() |>
    ggplot(aes(x = Var1, y = Var2, fill = value)) +
    labs(title = "Variable Correlation Heat Map",
         x = "" ,
         y ="") +
    theme(axis.text.x = element_text(angle = 45,
                                     vjust = 0.5,
                                     hjust = 0.5)) + 
     geom_tile()

#save plot to output file
ggsave("../output/variable_correlation_heat_map.pdf",
       width = 10,
       height = 7)
```

Next create some exploratory plots to explore data and answer questions

## Data exploratory plots

```{r}
#distribution of daily sent variable
full_data |>
  ggplot(mapping = aes(x = daily_sent)) +
  geom_density() +
  labs(title = "Distribution of Daily Sentiment Variable", 
       x = "Daily Sentiment", 
       y = "") +
  theme_minimal()

#save plot to output file
ggsave("../output/distribution_of_daily_sent.pdf",
       width = 10,
       height = 7)


#PE ratios over time
full_data |>
  ggplot(mapping = aes(y = pe_ratio, x = date)) +
  geom_line() +
  labs(title = "PE Ratio over Time Period", x = "Date", y = "PE Ratio") +
  theme_minimal()

#save plot to output file
ggsave("../output/pe_ratio_over_time.pdf",
       width = 10,
       height = 7)

#Distribution in change in PE ratios
full_data |>
  mutate(change_pe = pe_ratio - lag(pe_ratio, 1)) |> #add change in pe ratio variable
  ggplot(mapping = aes(x = change_pe)) +
  geom_density() +
  labs(title = "Distribution of Change in PE", x = "Change PE") +
  theme_minimal()

#save plot to output file
ggsave("../output/change_pe_ratio.pdf",
       width = 10,
       height = 7)


#distribution of headline observations over time
wsj_data_sent |>
  group_by(date) |>
  summarize(count = n()) |>
  ggplot(mapping = aes(x = date, y = count, color = weekdays(date))) +
  geom_point() +  
  labs(title = "Number of Articles by Day of Week",
       x = "Date",
       y= "Number of Articles",
       color = "Day of Week") +
  theme_minimal()

#save plot to output file
ggsave("../output/articles_by_day_of_week.pdf",
       width = 10,
       height = 7)
```

## Visualization of Exploratory Models

```{r}
#relationship between daily sentiment and pe ratio
full_data |>
  ggplot(mapping = aes(x = daily_sent, y = pe_ratio)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(title = "Daily Sentiment vs PE Ratio",
       x = "Daily Sentiment",
       y= "PE Ratio") +
  theme_minimal()

#save plot to output file
ggsave("../output/pe_ratio_vs_daily_sent.pdf",
       width = 10,
       height = 7)

#relationship between daily sentiment and change in pe ratio
full_data |>
  mutate(change_pe = pe_ratio - lag(pe_ratio, 1)) |> #add change in pe ratio variable
  ggplot(mapping = aes(x = daily_sent, y = change_pe)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(title = "Daily Sentiment vs Change in PE Ratio",
       x = "Daily Sentiment",
       y= "Change in PE Ratio") +
  theme_minimal()

#save plot to output file
ggsave("../output/change_pe_vs_daily_sent.pdf",
       width = 10,
       height = 7)
```

Summary table to data to be used in modeling

```{r}
#use stargazer to create summary table in publishable format
stargazer(full_data,
          type = "text",
          median = TRUE,
          digits = 2,
          title = "Summary of Data",
          out = "../output/data_summary.txt")
```

# Modeling

## Linear & Simple Auto Regression Models

The following models all attempt to help explain the relationship between the sentiment within the WSJ headlines and the market valuations. (note: RMSE is used to evaluate model accuracy as R squared is naturally very small, most market changes come from changes in economic conditions)

The first model that will be evaluated is a simple linear relationship between the PE ratio (market valuations) and daily_sent (WSJ headline sentiment)

```{r}
#linear model with pe_ratio as dependant and daily_sent as independant 
lm(pe_ratio ~ daily_sent, full_data) -> lm_4.1

#summary statistics is on model
summary(lm_4.1)

#RMSE calculation - 4.0488 in this case
sqrt(mean(lm_4.1$residuals^2))

#diagnostic plots for model
plot(lm_4.1) 
```

This first linear models shows a positive statistically significant coefficient for daily_sent as a explanatory variable for pe_ratio. This is a good first step but doesn't show causality as they occur simultaneous (happen on the same day). The next model seeks to establish causality by looking at sentiment on the previous day (t-1) as and explanatory variable for pe_ratio.

```{r}
#linear model with pe_ratio as dependant and daily_sent (t-1) as independant
lm(pe_ratio ~ lag(daily_sent, 1), full_data) -> lm_4.2
  
#summary statistics is on model
summary(lm_4.2)

#RMSE calculation - 4.0493
sqrt(mean(lm_4.2$residuals^2))

#diagnostic plots for model
plot(lm_4.2)
```

This second model has a very similar result with the independent variable daily_sent (t-1) have both a positive and statisticlly significant coefficient. It also helps to make the cause for causality by using the day before with sentiment data - previous daily news sentiment has a statically significant affect on pe_ratio.

A natural next step is to try different lengths of lag terms on the daily_sent variable to create more robust auto regression models. The Bayesian Information Criterion (BIC) is used to evaluate many different lengths of lag terms to select one that balances model accuracy with risk of over fitting.

The code chunk below is a function for running models of various lag lengths through the BIC formula. By this theory selecting the model that produces the lowest BIC value is optimal. Selecting nearby lengths with similar BIC's is acceptable to simplify the model.

```{r}
#BIC function
BIC <- function(model) {
  
  #extract model accuracy statistics
  ssr <- sum(model$residuals^2)
  t <- length(model$residuals)
  npar <- length(model$coef)
  
  return(
    round(c("p" = npar - 1, #length of lag term
          "BIC" = log(ssr/t) + npar * log(t)/t, #BIC formula result
          "Adj.R2" = summary(model)$adj.r.squared), 4) #adjusted r squared of model
    )
}
```

Next run this function on the last model form to optimize the length of lag term on daily_sent variable

```{r}
#how many different lag lengths to test (100 as top limit as any more become nonsensical)
order <- 1:100

#run model form through BIC function to create table lag length, BIC value, and adjusted R squared
BICs <- sapply(order, function(x) 
        BIC(dynlm(ts(full_data$pe_ratio) ~ L(ts(full_data$daily_sent), 1:x))))

#select the minimized lag length - most optimal from BIC formula
BICs[, which.min(BICs[2, ])]

```

The result of running the model for through the BIC function shows the most optimal length to lag for daily_sent is 1, or one day. This is the same as the previous lm_4.2 but can now select lag length of 1 with more confidence.

The PE ratio variable is a time series variable, it is heavily correlated with its own previous values. Incorporating previous pe_ratio values should improve the accuracy of the auto regression models and help control for this correlation.

First run the new model form with a lag on pe_ratio through the BIC function

```{r}
#how many different lag lengths to test (100 as top limit as any more become nonsensical)
order <- 1:100

#run model form through BIC function to create table lag length, BIC value, and adjusted R squared
BICs <- sapply(order, function(x) 
        BIC(dynlm(ts(full_data$pe_ratio) ~ L(ts(lag(full_data$daily_sent,1))) + L(ts(full_data$pe_ratio), 1:x))))

#select the minimized lag length - most optimal from BIC formula
BICs[, which.min(BICs[2, ])]

```

Optimal lag length is 4 from this run on BIC however the actual difference in BIC value from the optimal 4 length and much simpler 1 length is small (0.0039) so I will run a model at lag length 4 and lag length 1 to compare accuracy and see if added complexity is worth it.

```{r}
#model with 4 lag terms for pe_ratio
lm(pe_ratio ~ lag(daily_sent, 1) +
     lag(pe_ratio,1) +
     lag(pe_ratio,2) +
     lag(pe_ratio,3) +
     lag(pe_ratio,4), 
   full_data) -> ar_4.1

#summary statistics on model 
summary(ar_4.1)

#RMSE calculation - 0.3745
sqrt(mean(ar_4.1$residuals^2))

#diagnostic plots on model
plot(ar_4.1)



#model with only one lag term for pe_ratio
lm(pe_ratio ~ lag(daily_sent, 1) +
     lag(pe_ratio,1), 
   full_data) -> ar_4.2

#summary statistics on model 
summary(ar_4.2)

#RMSE calculation - 0.3764
sqrt(mean(ar_4.2$residuals^2))

#diagnostic plots on model
plot(ar_4.2)
```

The more optimal and complex model at lag length 4 is only marginally more accurate than simple lag length one model. The difference in RMSE of 0.002 is not worth the added complexity so lag length of one for pe_ratio will be used moving forward.

## De-Trended Models

Another method to incorporate the time nature of the data is to de-trend the independent pe_ratio variable. This will change the model to be predicting residuals from a moving average instead of the actual pe_ratio itself. This study will de-trend using both a weekly and monthly moving average. The next code chunk creates the moving average variables and residuals on weekly and monthly bases (note: this study focuses on trading days - 5 days a week - 20 days a month).

```{r}
#create weekly and monthly detrended variables for pe_ratio
#add weekly MA to full data and detrended variable (weekly_ma_res)
full_data |>
  mutate(weekly_ma = (lag(pe_ratio, 1) + #create weekly moving average
                        lag(pe_ratio, 2) +
                        lag(pe_ratio, 3) +
                        lag(pe_ratio, 4) +
                        lag(pe_ratio, 5)) / 5) |>
  mutate(weekly_ma_res = pe_ratio - weekly_ma) -> #create residaul from moving average
  full_data

#add monthly MA to full data and dretrended variable (montly_ma_res)
full_data |>
  mutate(monthly_ma = (lag(pe_ratio, 1) + #create monthly moving average
                        lag(pe_ratio, 2) +
                        lag(pe_ratio, 3) +
                        lag(pe_ratio, 4) +
                        lag(pe_ratio, 5) +
                        lag(pe_ratio, 6) +
                        lag(pe_ratio, 7) +
                        lag(pe_ratio, 8) +
                        lag(pe_ratio, 9) +
                        lag(pe_ratio, 10) +
                        lag(pe_ratio, 11) +
                        lag(pe_ratio, 12) +
                        lag(pe_ratio, 12) +
                        lag(pe_ratio, 14) +
                        lag(pe_ratio, 15) +
                        lag(pe_ratio, 16) +
                        lag(pe_ratio, 17) +
                        lag(pe_ratio, 18) +
                        lag(pe_ratio, 19) +
                        lag(pe_ratio, 20)) / 20) |>
  mutate(monthly_ma_res = pe_ratio - monthly_ma) -> #create residual from moving average
  full_data
```

Create a graph of pe_ratio, weekly moving average, and monthly moving average

```{r}
#graph for pe ratio and MA's
full_data |>
  slice(1:250) |> #focus on last 250 value of time period to zoom in 
  ggplot(mapping = aes(x = date)) +
  geom_line(mapping = aes(y = pe_ratio, color = "pe_ratio")) +     
  geom_line(mapping = aes(y = weekly_ma, color = "weekly_ma")) +
  geom_line(mapping = aes(y = monthly_ma, color = "monthly_ma")) +
  scale_color_manual(values = c(
    "pe_ratio" = "black",       # color for PE Ratio line
    "weekly_ma" = "green2",     # color for Weekly MA line
    "monthly_ma" = "blue" )) +  # color for Monthly MA line
  labs(title = "PE Ratio & Moving Averages",
       x = "Date",
       y= "PE Ratio",
       color = "Legend") +
  theme_minimal() 
  
#save plot to output file
ggsave("../output/pe_ratio_&_moving_averages.pdf",
       width = 10,
       height = 7)
```

Graphs of residuals after both weekly and monthly de-trending

```{r}
#weekly ma 
#line graph of detrended weekly ma residuals
full_data |>
  slice(1:250) |> #same time period to demonstrate detrending
  ggplot(mapping = aes(x = date)) +
  geom_line(mapping = aes(y = weekly_ma_res)) +
  geom_hline(yintercept = 0, color = "red") + # horizontal line at y = 0
  labs(title = "De-trended weekly moving average PE residuals",
       x = "Date",
       y= "PE Residual") +
  theme_minimal() 

#save plot to output file
ggsave("../output/de-trended_weekly_pe_line.pdf",
       width = 10,
       height = 7)

#histogram of detrended weekly ma residuals
full_data |>
  ggplot(mapping = aes(x = weekly_ma_res)) +
  geom_density() +
  labs(title = "De-trended weekly moving average PE residuals distribution",
       x = "Weekly Moving Average PE Residulas",
       y = "") +
  theme_minimal()

#save plot to output file
ggsave("../output/de-trended_weekly_pe_histogram.pdf",
       width = 10,
       height = 7)


#monthly ma 
#line graph of detrended monthly ma residuals
full_data |>
  slice(1:250) |> #same time period to demonstrate detrending
  ggplot(mapping = aes(x = date)) +
  geom_line(mapping = aes(y = monthly_ma_res)) +
  geom_hline(yintercept = 0, color = "red") + # horizontal line at y = 0
  labs(title = "De-trended monthly moving average PE residuals",
       x = "Date",
       y= "PE Residual") +
  theme_minimal() 

#save plot to output file
ggsave("../output/de-trended_monthly_pe_line.pdf",
       width = 10,
       height = 7)

#histogram of detrended monthly ma residuals
full_data |>
  ggplot(mapping = aes(x = monthly_ma_res)) +
  geom_density() +
  labs(title = "De-trended monthly moving average PE residuals distribution",
       x = "Monthly Moving Average PE Residuals",
       y = "") +
  theme_minimal()

#save plot to output file
ggsave("../output/de-trended_monthly_pe_histogram.pdf",
       width = 10,
       height = 7)
```

Is de-trended PE easier to predict on weekly or monthly basis than normal pe_ratio?

Will need to optimize BIC again for lag length on weekly and monthly de-trended autocorrelation predictors

Start with the weekly de-trended pe_ratio

```{r}
#weekly BIC optimization
#how many different lag lengths to test
order <- 1:100

#test models of different lage lengths for detrended PE ratio
#removed rows with N/As
BICs <- sapply(order, function(x) 
        BIC(dynlm(ts(full_data$weekly_ma_res[6:2516]) ~ L(ts(lag(full_data$daily_sent[6:2516],1))) + L(ts(full_data$weekly_ma_res[6:2516]), 1:x))))

#select the minimized lag length - most optimal from BIC formula
BICs[, which.min(BICs[2, ])]
```

The optimal BIC value is a lag length of 4 for weekly de-trended pe_ratio. There is still not a large difference BIC value for lag length of 4 and 1, 0.0153, so the simpler model with lag length of one will be used in the future.

Next run BIC formula on monthly de-trended pe ratio

```{r}
#monthly BIC optimization
#how many different lag lengths to test
order <- 1:100

#test models of different lage lengths for detrended PE ratio
#removed rows with N/As
BICs <- sapply(order, function(x) 
        BIC(dynlm(ts(full_data$monthly_ma_res[21:2516]) ~ L(ts(lag(full_data$daily_sent[21:2516],1))) + L(ts(full_data$monthly_ma_res[21:2516]), 1:x))))

#select the minimized lag length - most optimal from BIC formula
BICs[, which.min(BICs[2, ])]
```

The optimal BIC value is a lag length of 15 for the monthly de-trended pe_ratio. While this is a much larger lag length than the 4 recommended for weekly de-trended pe_ratio the simpler model with lag length of 1 is still preferred as the difference in BIC value of 0.0207 is still not significant.

Create auto regression models for predicting de-trended weekly and monthly pe_ratios

```{r}
#model for weekly de-trended PE
lm(weekly_ma_res ~ lag(daily_sent, 1) +
     lag(weekly_ma_res,1), 
   full_data) -> ar_4.3

#summary statistics on model 
summary(ar_4.3)

#RMSE calculation - 0.3810
sqrt(mean(ar_4.3$residuals^2))

#diagnostic plots on model
plot(ar_4.3)

#model for monthly de-trended PE
lm(monthly_ma_res ~ lag(daily_sent, 1) +
     lag(monthly_ma_res,1), 
   full_data) -> ar_4.4

#summary statistics on model 
summary(ar_4.4)

#RMSE calculation - 0.3842
sqrt(mean(ar_4.4$residuals^2))

#diagnostic plots on model
plot(ar_4.4)
```

Both these models do have strong predictability but produce higher RMSE than model ar_4.2 at RMSE value of 0.3764. For ease of interpretation and improved accuracy it is better to use pe_ratio as independent variable instead of either monthly or weekly de-trended pe_ratios.

## Topical Models

The last model form this study examines is to separate from the overall average headline sentiment the sentiment from specific journal columns. For example create a variable for the daily sentiment of all article headlines published under the "Business" column. This will show topical affects and explore if any own section of the overall WSJ has a strong impact on valuations. There were 2013 unique columns published under during the time period this study examines. To narrow down this list only columns that published at least 4 articles of day will be separated out in this way (4 articles \* 250 days \* 10 years = 10,000 headlines). Once these new daily_sent variables are created a model that uses each as a dependent variable will be made to explore the relationships.

```{r}
#duplicate full_data for seperate analysis
full_data -> full_data_sec

#get headline columns with at least 4 a day (10 years * 250 days * 4 articles = 10,000 article)
wsj_data_sent |>
  group_by(column) |>
  summarise(count = n()) |>
  filter(count >= 10000) -> top_columns

#make data set of each of the top_colums continaing headlines and sentiment 
for(i in top_columns$column){
  wsj_data_sent |>
    filter(column == i) -> temp
    assign(paste("column_data_", i, sep = ""),temp)
}

#add a column to the full data set for each of the topics
for(i in top_columns$column) {
  #first average sentiment by day and rename column with topic
  get(paste("column_data_", i, sep = "")) |>
    mutate(date = parse_date_time(str_extract(
    date, 
    pattern = "[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]"),
    orders = "ymd")) |>
    select(sentiment, date) |>
    group_by(date) |>
    summarise(daily_sent = mean(sentiment)) |>
    rename_with(~paste("daily_sent_", i, sep = ""), .cols = c(daily_sent)) |>
    janitor::clean_names()-> temp
  
  #join new column onto the orginal data set 
  full_data_sec |>
    mutate(date = parse_date_time(str_extract(
    date, 
    pattern = "[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]"),
    orders = "ymd")) |>
    full_join(temp, by = c("date")) -> full_data_sec
}
```

Top columns by number of articles published are:

-   Business

-   Commentary

-   Heard on the Street

-   Letters

-   Politics

-   Review and Outlook

-   Tech

-   U.S.

-   World

Create an auto regression model with each of the top journal columns daily_sent as dependent variables. Use a lag length of one to match previous findings to show causality.

```{r}
#model with top column sentiments
lm(pe_ratio ~ lag(daily_sent, 1) +
     lag(daily_sent_business, 1 ) +
     lag(daily_sent_commentary, 1) +
     lag(daily_sent_heard_on_the_street, 1) +
     lag(daily_sent_letters, 1) +
     lag(daily_sent_markets, 1) +
     lag(daily_sent_politics, 1) +
     lag(daily_sent_review_outlook, 1) +
     lag(daily_sent_tech, 1) +
     lag(daily_sent_u_s, 1) +
     lag(daily_sent_world, 1) +
     lag(pe_ratio,1), 
   full_data_sec) -> ar_4.5

#summary statistics on model 
summary(ar_4.5)

#RMSE calculation - 0.3767
sqrt(mean(ar_4.5$residuals^2))

#diagnostic plots on model
plot(ar_4.5)
```

While this model does not show any statistical significance on the coefficients for any daily_sent variable it is still highly predictive and useful to compare which journal columns affect the markets more. It is possible the lagged pe_ratio variable is overshadowing affects of the daily_sent variables so running the same model without it could improve the ability to make such conclusions

```{r}
#model with top column sentiments
lm(pe_ratio ~ lag(daily_sent, 1) +
     lag(daily_sent_business, 1 ) +
     lag(daily_sent_commentary, 1) +
     lag(daily_sent_heard_on_the_street, 1) +
     lag(daily_sent_letters, 1) +
     lag(daily_sent_markets, 1) +
     lag(daily_sent_politics, 1) +
     lag(daily_sent_review_outlook, 1) +
     lag(daily_sent_tech, 1) +
     lag(daily_sent_u_s, 1) +
     lag(daily_sent_world, 1),
   full_data_sec) -> ar_4.6

#summary statistics on model 
summary(ar_4.6)

#RMSE calculation - 4.1447
sqrt(mean(ar_4.6$residuals^2))

#diagnostic plots on model
plot(ar_4.6)
```

This last model is not very accurate, particularly when sentiment is positive, however does show statistical significance on the journal columns: Markets, World, Politics, and Tech implying they might have a bigger affect on changes in valuations than any other journal topic.

## Final Table

These last code chunks produce a publishable table to compares all the summary statistics of all models created in this study

```{r}
# gather robust standard errors in a list
rob_se <- list(sqrt(diag(vcovHC(lm_4.1, type = "HC1"))),
               sqrt(diag(vcovHC(lm_4.2, type = "HC1"))),
               sqrt(diag(vcovHC(ar_4.1, type = "HC1"))),
               sqrt(diag(vcovHC(ar_4.2, type = "HC1"))),
               sqrt(diag(vcovHC(ar_4.3, type = "HC1"))),
               sqrt(diag(vcovHC(ar_4.4, type = "HC1"))),
               sqrt(diag(vcovHC(ar_4.5, type = "HC1"))),
               sqrt(diag(vcovHC(ar_4.6, type = "HC1"))))

#the stargazer function will sometimes break with longer function names 
#so this is to make them shorter 
L1 <- lm_4.1
L2 <- lm_4.2
A1 <- ar_4.1
A2 <- ar_4.2
A3 <- ar_4.3
A4 <- ar_4.4
A5 <- ar_4.5
A6 <- ar_4.6

#create publishing table of all models
stargazer(L1, L2, A1, A2, A3, A4, A5, A6,
          type = "text", 
          se = rob_se,
          digits = 3,
          column.labels = c("(LM 1)", "(LM 2)", "(AR 1)", "(AR 2)", "(AR 3)", "(AR 4)", "(AR 5)", "(AR 6)"),
          out = "../output/models_summary_4.0.txt")
```
