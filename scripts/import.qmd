---
title: "Data Import Script"
format: html
---

# Libraries and Packages

Install needed packages for data import and collection

```{r packages}
install.packages("tidyverse")
install.packages("rvest")
install.packages("chromote")
library(tidyverse)
library(rvest)
library(chromote)
```

# Data Collection

Data for this project will consist of all headlines from the Wall Street Journal over the last ten years (January 1, 2015 through December 31, 2024). The resulting data set will have variables for title, date publication, and journal column. The intent is to web scrape the WSJ archives (<https://www.wsj.com/news/archive/years>) by cycling through every year, month and day in the target range.

To evaluate how news sentiment effects the markets daily stock market prices and valuations based on the S&P500 will be obtained from a variety of websites.

## Web-scrapping

The first web scrapping task will create a data set from the Wall Street Journal archives

```{r}
#url for Wall Street Journal archives
wsj_url <- "https://www.wsj.com/news/archive/years"


#open headless browser tab and navigate to WSJ archive page
options(chromote.headless = "new") #set option to use new headless mode
brow <- ChromoteSession$new()
brow$view()
brow$Page$navigate(wsj_url)
brow$Page$loadEventFired() #pasues R functions until page loads

#get list of all links to archive months
read_html(wsj_url)|>
  html_elements(".WSJTheme--month-link--1N8tTFWa") |>
  html_attr("href") |>
  enframe(name = NULL, value = "month") |>
  filter(str_detect(month, 
                    pattern = paste(c(as.character(c(2015:2024))), collapse = "|"))) |>
  mutate(full_urls = paste("https://www.wsj.com", month, sep = "")) ->
  month_urls

x <- 1
daily_urls <- tibble(full_urls = character())
while (x <= length(month_urls$full_urls)) {
  #open month browser section
  brow_month <- brow$new_session()
  brow_month$Page$navigate(month_urls$full_urls[x])
  brow_month$Page$loadEventFired()
  
  #add urls of days to data set
  read_html(month_urls$full_urls[x]) |>
    html_elements(".WSJTheme--day-link--19pByDpZ") |>
    html_attr("href") |>
    enframe(name = NULL, value = "day") |>
    mutate(full_daily_urls = paste(month_urls$full_urls[x], day, "")) ->
    temp_data
  
  #add daily urls from month to final tibble
  y <- 1
  while(y <= length(temp_data$full_daily_urls)){
      add_row(daily_urls, full_urls = temp_data$full_daily_urls[y]) ->
      daily_urls
      y <- y +1
  }
  
  #close chromate tab
  brow_month$close()
  
  x <- x + 1
}

#remove loop items from environment
rm(brow_month)
rm(x)
rm(y)
rm(temp_data)

#close current tab
brow$close()

#shut down browser
brow$parent$close()
```
