---
title: "Data Cleaning Script"
format: html
---

# Libraries and Packages

Install and load needed packages for data cleaning

```{r packages}
install.packages("tidyverse")  #for general tidyverse functions
install.packages("sentimentr") #for calculating the sentiment score of headlines
library(tidyverse)
library(sentimentr)
```

# Load Data Sets

Load in data sets from import data folder

```{r}
#laod in wsj_data
read_csv("../data/imported_data/full_wsj_data.csv") ->
  wsj_data

#load in spy_data
read_csv("../data/imported_data/spy_data.csv") ->
  spy_data

#load in pe_data
read_csv("../data/imported_data/pe_ratio.csv") -> 
  pe_data
```

# WSJ Data

Cleaning WSJ data to extract data from URL and add in sentiment score

```{r}
#extract date from url column and format as date time object
wsj_data |>
  mutate(date = parse_date_time(str_extract(
    wsj_data$url, 
    pattern = "[0-9][0-9][0-9][0-9]/[0-9][0-9]/[0-9][0-9]"),
    orders = "ymd")) ->
  wsj_data


#add sentiment scores utilizing sentimentr::sentiment_by() function
wsj_data |>
  mutate(sentiment = sentiment_by(headlines)) ->
  wsj_data_sent

#remove unneeded columns generated by the sentiment_by() function
wsj_data_sent |>
  unnest_wider(sentiment) |>
  select(-element_id, -word_count, -sd) |>
  rename(sentiment = ave_sentiment) ->
  wsj_data_sent


#save new csv file to cleaned file
write_csv(x = wsj_data_sent,
          file = "../data/cleaned_data/wsj_data_sent.csv")
```

# P/E Data

Take monthly data and create daily observations by extracting the earnings from the monthly PE data point. Then create daily PE ratios by dividing the price of the S&P 500 by the earnings

```{r}
#making date variables - extract month and year from the original date time object
pe_data |> 
  mutate(month = month(date),
         year = year(date)) ->
  pe_data

#get price on first day of month to find earnings
spy_data |>
  #parse character date variable to date time object
  mutate(date = parse_date_time(date, orders = "mdy")) |>
  #extract month and year from date time object
  mutate(month = month(date),
         year = year(date)) |>
  #join with pe_data by month and year columns
  inner_join(pe_data, by = c("month", "year")) |>
  group_by(year, month) |>
  arrange(date.x, .by_group = TRUE) |>
  #select the price on the first day of the month
  slice(1) |>
  #isolate earnings from price and pe ratio 
  mutate(earnings = price/pe_ratio) |>
  select(month, year, earnings) |>
  inner_join(pe_data, by = c("month", "year")) ->
  pe_data

#save new csv file to cleaned file
write_csv(x = pe_data,
          file = "../data/cleaned_data/pe_data.csv")
```

# Full Data File Creation

Add sentiment score and pe_ratio data to spy_data

```{r}
#get daily sentiment from wsj_data_sent, average sentiment from all published headlines in a day
wsj_data_sent |>
  group_by(date) |>
  summarise(daily_sent = mean(sentiment)) |>
  select(date, daily_sent) ->
  daily_sent

#parse change_percent column to a double data type
spy_data |>
  mutate(change_percent = parse_number(change_percent)/100) ->
  spy_data

#starting with spy_data file join variables of interest from daily_sent and pe_data 
spy_data |>
  mutate(date = parse_date_time(date, orders = "mdy")) |>
  inner_join(daily_sent, by = c("date")) |>
  mutate(month = month(date),
         year = year(date)) |>
  inner_join(pe_data, by = c("month", "year")) |>
  mutate(pe_ratio = price/earnings) |>
  select(-date.y, -month, -year, -earnings) |>
  rename(date = date.x) -> full_data

#write full data to cleaned data folder
write_csv(x = full_data,
          file = "../data/cleaned_data/full_data.csv")
```
